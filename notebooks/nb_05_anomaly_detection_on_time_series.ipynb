{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-output",
     "remove-input-nbconv",
     "remove-output-nbconv"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tfl_training_anomaly_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload_ext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtfl_training_anomaly_detection\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2454\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2456\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/magics/extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_str:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing module name.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malready loaded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m extension is already loaded. To reload it, use:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m module_str)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/extensions.py:62\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/extensions.py:77\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[0;32m---> 77\u001b[0m         mod \u001b[38;5;241m=\u001b[39m \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     mod \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[module_str]\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tfl_training_anomaly_detection'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext tfl_training_anomaly_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-input-nbconv"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%presentation_style` not found.\n"
     ]
    }
   ],
   "source": [
    "%presentation_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-output",
     "remove-input-nbconv",
     "remove-output-nbconv"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%set_random_seed 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input-nbconv",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%load_latex_macros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection on Time Series\n",
    "<img src=\"_static/images/aai-institute-cover.png\" alt=\"Snow\" style=\"width:100%;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/yjqm1szs7f98bfmhnyrvk_hw0000gn/T/ipykernel_1502/2963986727.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.graphics import tsaplots\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "---\n",
    "\n",
    "**Definition:**\n",
    "A time series is a series of data points indexed by time. Most often\n",
    "the series contains points successively and equally spaced in time, e.g. every day, every month etc.\n",
    "\n",
    "---\n",
    "**Example:** Monthly beer production in Austria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "beer = pd.read_csv('../data/time_series/monthly-beer-production-in-austr.csv', index_col='Month')\n",
    "\n",
    "beer.plot()\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Why are Time Series Different?\n",
    "- Random events that occur over time highly influence the future behavior of most time series $\\Rightarrow$ time series\n",
    "  can only be predicted to a limited extent.\n",
    "- Spacial data is usually drawn independently, but the readings of a time series are correlated over time\n",
    "  (autocorrelation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def reg_forecast():\n",
    "    fig, axes = plt.subplots(nrows=2, figsize=(10, 10))\n",
    "\n",
    "    ax_reg = axes[0]\n",
    "    axes_tmsrs = axes[1]\n",
    "\n",
    "    # Regression\n",
    "    f = lambda x: (.5 * x) + 2\n",
    "\n",
    "    ax_reg.plot([0, 10], [f(0), f(10)])\n",
    "\n",
    "    n_sample = 30\n",
    "    X = np.random.rand(n_sample) * 10\n",
    "    y = f(X) + np.random.normal(0, .5, n_sample) # Noisy measurements\n",
    "    ax_reg.scatter(X, y, color='g')\n",
    "\n",
    "    lin = LinearRegression()\n",
    "    lin.fit(X.reshape(-1, 1), y)\n",
    "    X_pred = np.array([[0], [10]])\n",
    "    y_pred = lin.predict(X_pred)\n",
    "\n",
    "    ax_reg.plot(X_pred, y_pred, 'r--')\n",
    "    ax_reg.set_title('Regression')\n",
    "    ax_reg.legend(['True Function', 'Estimated Function', 'Noisy Measurements'])\n",
    "    # Time Series Forecasting\n",
    "    n_sample = 30\n",
    "    autoreg = lambda x: (np.array([.7, .1])*x).sum() + np.random.normal(0, 2)\n",
    "    series = [5, 3, 1, 1, 1, 1, 5, 5, 3]\n",
    "    for _ in range(n_sample-9):\n",
    "        series.append(autoreg(np.array([series[-1] - series[-8], series[-2] - series[-9]])) + series[-7])\n",
    "\n",
    "    series = pd.Series(series, index=pd.date_range(\"2018-01-01\", periods=n_sample, freq=\"D\"))\n",
    "    series.plot(ax=axes_tmsrs)\n",
    "    sarima = sm.tsa.statespace.SARIMAX(series, order=(2,0, 0), seasonal_order=(0, 1, 0, 7))\n",
    "    res = sarima.fit()\n",
    "    pred = res.get_prediction(start='2018-01-31', end='2018-02-28') #, dynamic='2018-02-01')\n",
    "    pred.predicted_mean.plot(style='r--', ax=axes_tmsrs)\n",
    "    conf_int = pred.conf_int()\n",
    "    axes_tmsrs.fill_between(conf_int.index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='r', alpha=.2)\n",
    "    axes_tmsrs.set_title('Time Series Forecasting')\n",
    "    axes_tmsrs.legend(['Past Readings', 'Forecast Mean', 'Forecast Confidence Interval'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "reg_forecast()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Types of Anomalies\n",
    "Because of the special nature of time series, we need to distinguish different types of anomalies:\n",
    "- Point anomalies\n",
    "- Context anomalies + change points\n",
    "- Pattern anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Point Anomalies\n",
    "If a point differs substantially from the rest of the data, we speak of a point anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 5))\n",
    "sample = np.random.normal(0, 1, 100)\n",
    "sample[50] = 10\n",
    "ax.plot(sample)\n",
    "circ = plt.Circle((50, 10), radius=3, color='red', fill=False)\n",
    "ax.add_patch(circ)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend([circ], ['Point Anomaly'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Context Anomalies and Change Points\n",
    "- Context anomalies appear abnormal in their context but could be normal readings in a different context.\n",
    "- Change points mark regime shifts in the underlying data generation process.\n",
    "Time series with regime shifts are one example where context anomalies can appear, but they can also be found when the time series\n",
    "shows for instance a seasonal pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 5))\n",
    "sample = np.random.normal(0, 1, 30)\n",
    "sample = np.concatenate([sample, np.random.normal(10, 1, 30)])\n",
    "sample = np.concatenate([sample, np.random.normal(0, 1, 30)])\n",
    "sample[50] = 0\n",
    "\n",
    "ax.plot(sample)\n",
    "circ_anml = plt.Circle((50, 0), radius=3, color='red', fill=False)\n",
    "ax.add_patch(circ_anml)\n",
    "circ_chngpnt = Ellipse((29.5, 5), width=2, height=15, color='green', fill=False)\n",
    "ax.add_patch(circ_chngpnt)\n",
    "circ_chngpnt = Ellipse((59.5, 5), width=2, height=15, color='green', fill=False)\n",
    "ax.add_patch(circ_chngpnt)\n",
    "ax.legend([circ_anml, circ_chngpnt], ['Context Anomaly', 'Changepoint'])\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pattern Anomalies\n",
    "Also, a pattern formed by several points might be anomalous while the individual points don't show abnormal readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 5))\n",
    "sample = np.random.normal(0, 5, 45)\n",
    "sample = np.concatenate([sample, np.zeros(10)])\n",
    "sample = np.concatenate([sample, np.random.normal(0, 5, 45)])\n",
    "sample[50] = 0\n",
    "\n",
    "ax.plot(sample)\n",
    "circ = plt.Circle((49, 0), radius=5, color='red', fill=False)\n",
    "ax.add_patch(circ)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend([circ], ['Pattern Anomaly'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Time Series as Stochastic Processes\n",
    "A time series can often be seen as a realization of a stochastic process where each observation is a realization of a\n",
    "random variable $(X_t)_{t\\in \\mathbb{N}}$.\n",
    "Important properties:\n",
    "- $E[X_t]$\n",
    "- $\\mathrm{Var}[X_t] = E[(X_t - E[X_t])^2]$\n",
    "- $\\mathrm{Cov}[X_t, X_{t'}] = E[(X_t - E[X_t])(X_{t'} - E[X_{t'}])]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stationarity\n",
    "A central property in time series analysis is *stationarity*.\n",
    "\n",
    "---\n",
    "**Definition:** A time series is (covariance) stationary if the following three conditions are fulfilled:\n",
    "- Constant Mean: $E[X_t] = \\mu$ $\\forall t\\in \\mathbb{N}$\n",
    "- Constant variance: $\\mathrm{Var}[X_t] = \\sigma^2 $ $\\forall t\\in \\mathbb{N}$\n",
    "- Time invariant covariance: $\\mathrm{Cov}[X_t, X_{t+k}] = \\lambda_k$ $\\forall t,k\\in \\mathbb{N}$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why Stationarity?\n",
    "**Example**: Simple autoregressive Processes (AR(1))\n",
    "The difference between stationary and non-stationary processes can be understood by\n",
    "considering processes of the form $X_t = \\phi X_{t-1} + \\epsilon_{t}$ where the $\\epsilon_t$ are\n",
    "normally distributed i.i.d. variables.\n",
    "Depending on the value of $\\phi$ we get very different behaviors:\n",
    "- $|\\phi| > 1$: explosive process (non-stationary but rarely observed in practice)\n",
    "- $|\\phi| = 1$: random walk (non-stationary)\n",
    "- $|\\phi| < 1$: stationary process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stationary vs Non-Stationary Time Series\n",
    "The latter two cases are the relevant ones in practice. Let us have a look at the following processes:\n",
    "- $X_t = X_{t-1} + \\epsilon_t$\n",
    "- $Y_t = \\frac{4}{5} Y_{t-1} + \\epsilon'_t$\n",
    "\n",
    "where $\\epsilon_t, \\epsilon'_t\\sim \\mathcal{N}(0, 1)$ are independent white noise processes.\n",
    "We simulate both processes several times with the same initial condition $X_0=Y_0=25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 7))\n",
    "\n",
    "for _ in range(5):\n",
    "    # random walk\n",
    "    walk = [25]\n",
    "    for i in range(1000):\n",
    "        walk.append(walk[-1] + np.random.normal(0, 1))\n",
    "\n",
    "    # stationary time series\n",
    "    series = [25]\n",
    "    for i in range(1000):\n",
    "        series.append((4/5) * series[-1] + np.random.normal(0,1))\n",
    "\n",
    "    ax.plot(walk, color='b')\n",
    "    ax.plot(series, color='g')\n",
    "    ax.legend(labels=['Random walk (non-stationary)', \"Stationary autoregressive process\"], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stationary vs Non-Stationary Time Series\n",
    "While a stationary process always reverts to its mean ($0$ for $Y_t$), the non-stationary random walk can move\n",
    "unpredictably in any direction. This is because the random events of past do not wear off over time in a random walk.\n",
    "Hence, the variance increases over time which makes it hard to define anomalous behavior.\n",
    "Indeed,\n",
    "\n",
    "- $E[X_{t+k} \\mid X_t] = X_t$ but\n",
    "- $\\lim_{k\\to\\infty}E[Y_{t+k} \\mid Y_t] = 0$.\n",
    "\n",
    "**Question:** Can you explain why the expectations behave that way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stationary vs Non-Stationary Time Series\n",
    "In these situations it is often a better idea to analyze the white noise process $\\epsilon_t$.\n",
    "In our example we can rearrange the definition of $X_t$ to get\n",
    "\n",
    "<center>\n",
    "\n",
    "$\\epsilon_t = X_t - X_{t-1}$\n",
    "</center>\n",
    "\n",
    "The *lag* operator is defined as $L(X_t) = X_{t-1}$. Using the lag operator we can write the above equation as\n",
    "\n",
    "<center>\n",
    "\n",
    "$\\epsilon_t = (1-L)X_t$\n",
    "\n",
    "</center>\n",
    "\n",
    "We will see that this operation plays a special role in time series analysis. First let us see what this does to our\n",
    "random walk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stationary vs Non-Stationary Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "w0 = np.array(walk[1:]) - np.array(walk[:-1])\n",
    "plt.plot(w0)\n",
    "plt.gca().set_title(\"Differenced Series\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We see a pure white noise process with a well defined behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Although many algorithms assume stationarity of the time series, in practice it is more common to find non-stationary\n",
    "time series. Probably the most common cause for non-stationarity are trends and seasonality. In the following we will\n",
    "discuss methods to identify and remove them from a time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trends\n",
    "---\n",
    "**Definition**\n",
    "A trend in a time series is a tendency to move to relatively higher (or lower) values that is observed over a\n",
    "long period of time.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "shampoo = pd.read_csv('../data/time_series/sales-of-shampoo-over-a-three-ye.csv', index_col='Month')\n",
    "\n",
    "shampoo.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Removing Trends\n",
    "The trend at time $t$ can be estimated by a moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "shampoo_mvgavg = shampoo.rolling(window=12).mean()\n",
    "shampoo_mvgavg.columns = ['Mvg avg of shampoo sales']\n",
    "shampoo_mvgavg.plot()\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question:** How would you describe the trend? How would you approach removing it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Removing Trends\n",
    "We can remove trends from a time series through differencing. The differencing operator $\\nabla$ is defined as\n",
    "\n",
    "\\begin{align*}\n",
    "  \\nabla(X_t) &= (1 - L)X_t \\\\\n",
    "              &= X_t - L(X_t) \\\\\n",
    "              &= X_t - X_{t-1}\n",
    "\\end{align*}\n",
    "\n",
    "$L(X_t) = X_{t-1}$ is the *lag operator*. The $k$th order differenced time series is hence:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\nabla^k(X_t) &= (1 - L)^kX_t \\\\\n",
    "              &= \\sum_{i=0}^k (-1)^i{k \\choose i} L^iX_t\n",
    "\\end{align*}\n",
    "\n",
    "- If a time series has a linear trend then the differenced time series will have no trend.\n",
    "- More generally, if a time series has a kth order polynomial trend the k-fold differenced time series will have no trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We take our shampoo sales example and apply the differencing operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "shampoo_dif = shampoo - shampoo.shift(1) # shift(k) ~ L^k\n",
    "\n",
    "# Estimate trend\n",
    "shampoo_dif.rolling(12).mean().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can see that there is still a linear trend in the series. Therefore, we apply the 2nd order differencing operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "shampoo_dif = shampoo - 2*shampoo.shift(1) + shampoo.shift(2) # (1-L)^2 = 1 - 2*L + L^2\n",
    "\n",
    "# Estimate trend\n",
    "shampoo_dif.rolling(12).mean().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now there is no trend apparent anymore. This is consistent with our initial inspection of the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Seasonalities\n",
    "---\n",
    "**Definition:**\n",
    "A seasonality is a cyclic behavior with a fixed interval length, e.g. a year, a month, etc.\n",
    "\n",
    "---\n",
    "**Example:** Minimum daily temperature in Melbourne, Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "temperatures = pd.read_csv('../data/time_series/daily-minimum-temperatures-in-me.csv', index_col='Date')\n",
    "temperatures.index = pd.to_datetime(temperatures.index)\n",
    "\n",
    "temperatures.plot()\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The time series has a clear 12-month seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Removing Seasonalities\n",
    "Seasonalities can be identified using the *autocorrelation function (acf)*. The acf describes the\n",
    "correlation between a variable and lagged version of itself, that is for stationary process\n",
    "with constant mean $\\mu$ and constant variance $\\sigma^2$\n",
    "\n",
    "$\\mathrm{acf}_X(k) = Corr(X_t, X_{t+k}) = \\frac{E[(X_t - \\mu)(X_{t+k} -\\mu)]}{\\sigma^2}$\n",
    "\n",
    "We take a look at the acf of our temperatures dataset. Before we apply the acf, we remove leap days so that every\n",
    "year has 365 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "temperatures_noleap = temperatures.loc[~((temperatures.index.month == 2) & (temperatures.index.day == 29))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig = tsaplots.plot_acf(temperatures_noleap, lags=2*365)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Removing Seasonalities\n",
    "In the acf we can clearly see the annual periodicity. We can remove the annual periodicity through lag-k differencing.\n",
    "$$\\nabla_kX_t = (1 - L^k)X_{t}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "temperatures_dif = temperatures_noleap.diff(365)\n",
    "#temperatures_dif.columns = ['Adjusted temperatures']\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 3))\n",
    "ax0, ax1 = axes\n",
    "\n",
    "temperatures_dif.plot(ax=ax0)\n",
    "temperatures_dif.plot(ax=ax1, kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Removing Seasonalities\n",
    "After differencing of the time series, it looks approximately like a white noise process (i.e., all samples are drawn\n",
    "independently of a fixed Gaussian distribution).\n",
    "Computing the acf for the adjusted time series should show no significant auto correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig = tsaplots.plot_acf(temperatures_dif.dropna(), lags=2*365)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary\n",
    "- Time series data differs from point data in the sense that the readings are in general not independent of each other.\n",
    "- Stationarity is a central concept in time series analysis.\n",
    "- A time series can contain trends and seasonalities which demand special attention when one tries to identify anomalies.\n",
    "- Differencing is one class of time series transformations which allows eliminating trends and seasonalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Forecasting\n",
    "A very common approach for anomaly detection on time series is based on forecasting.\n",
    "The idea is that a good forecasting model should be able to predict the next reading rather accurately\n",
    "if no anomaly appears. An anomaly, however, should not be predicted accurately. Therefore, we can use the prediction\n",
    "error as an anomaly score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The SARIMA Model\n",
    "The SARIMA model is a very popular and well researched method for time series forecasting. The name SARIMA can be\n",
    "decomposed as follows:\n",
    "\n",
    "- S: Seasonal\n",
    "- AR: Autoregressive\n",
    "- I: Integrated\n",
    "- MA: Moving Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The AR Model\n",
    "A purely autoregressive model represents the current reading as a linear combination of past readings and a\n",
    "non deterministic error. It is specified as $\\mathrm{AR}(k)$ where k denotes the number of past readings to consider.\n",
    "Hence, the representation of the $\\mathrm{AR}(1)$ model that we have seen previously:\n",
    "\n",
    "$X_t - \\phi_1X_{t-1} = \\epsilon_t$ (or equivalently $(1- \\phi_1L)X_t = \\epsilon_t$)\n",
    "\n",
    "is a special case of the $\\mathrm{AR}(k)$ representation:\n",
    "\n",
    "$$ \\left(1 - \\sum_{i=1}^{k}\\phi_iL^i\\right)X_t = \\epsilon_t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Stationarity:**\n",
    "An $\\mathrm{AR}$ process $(1 - \\sum_{i=1}^{k}\\phi_iL^i)X_t = \\epsilon_t$ is stationary if all roots of the\n",
    "characteristic polynomial $(1 - \\sum_{i=1}^{k}\\phi_iz^i)$ over the complex numbers lie outside the unit circle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The MA Model\n",
    "The moving average model expresses the reading at time $t$ as a weighted average of past error terms.\n",
    "Hence, $\\mathrm{MA}(1)$ is written as\n",
    "\n",
    "$$ X_t = \\epsilon_t + \\psi_1 \\epsilon_{t-1} $$\n",
    "\n",
    "and in general $\\mathrm{MA}(k)$\n",
    "\n",
    "$$ X_t = \\left(1 + \\sum_{i=1}^k \\psi_iL^i\\right)\\epsilon_t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Stationarity:**\n",
    "$\\mathrm{MA}$ models are always stationary.\n",
    "\n",
    "**Question:** Do you see why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "Consider the hypothetical sales of earthquake survival kits. After an earthquake sales increase, the effect lasts off\n",
    "over time.\n",
    "\n",
    "Say the strength of the strongest earthquake in the region over a year has a binomial distribution, and the sales\n",
    "motivated by this year's earthquake season are proportional to the strength. We might model the situation as follows:\n",
    "- $\\epsilon_t \\sim 1000 \\cdot \\textrm{Binomial}(.5)$\n",
    "- $X_t = \\epsilon_t + \\sum_{i=1}^5 .9^i\\epsilon_{t-i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "shocks = np.abs(np.random.binomial(10, 0.2, 100))\n",
    "sales = [sum([shocks[t-lag]* 1000 * (.999**lag) for lag in range(6)]) for t in range(5, len(shocks))]\n",
    "\n",
    "_, axes = plt.subplots(nrows=2, sharex='all')\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(np.arange(5, len(shocks)), sales)\n",
    "ax.set_title(\"Kit sales\")\n",
    "\n",
    "ax=axes[1]\n",
    "ax.set_title('Earthquakes')\n",
    "ax.plot(shocks)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The ARMA Model\n",
    "Both models can be combined building the $\\mathrm{ARMA}(p, q)$ model:\n",
    "\n",
    "$$ \\left(1 - \\sum_{i=1}^p\\phi_i L^i\\right)X_t = \\left(1 + \\sum_{j=1}^q \\psi_j L^j\\right)\\epsilon_t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Idea:** Correct the autoregressive model using past prediction errors. For instance a local tendency to predict too\n",
    "low values can be corrected by adding an average of the last few prediction errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ARIMA Model\n",
    "It is advisable to apply ARMA models only to stationary time series. In fact most implementations enforce by default the\n",
    "model to be stationary. In case of a non-stationary time series\n",
    "we need the extensions to the ARIMA model.\n",
    "First, the $\\mathrm{ARIMA}(p, d, q)$ model applies d-th order differencing before applying $\\mathrm{ARMA}(p, q)$\n",
    "to remove trends from the time series\n",
    "\n",
    "$$ \\left(1 - \\sum_{i=1}^p\\phi_iL^i\\right)(1-L)^dX_t = \\left(1 + \\sum_{j=1}^q \\psi_jL^j\\right)\\epsilon_t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modeling of Seasonal influences\n",
    "Seasonal ARIMA further extends the model by seasonal term and is specified as $\\mathrm{SARIMA}(p, d, q)(P, D, Q)_m$.\n",
    "The parameters $p$, $d$, and $q$ have the same meaning as in $\\mathrm{ARIMA}(p, d, q)$ and $P$, $D$, and $Q$ are their\n",
    "seasonal counterparts. Explicitly\n",
    "- $P$ is the number of seasonal lags in the autoregressive part.\n",
    "- $D$ is the order of seasonal differencing that is applied.\n",
    "- $Q$ is the number of seasonally lagged error terms for the moving average part.\n",
    "- $m$ is the period of the seasonality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To obtain the full model the seasonal terms are simply multiplied by the non-seasonal terms. That means\n",
    "$\\mathrm{SARIMA}(p, d, q)(P, D, Q)_m$ can be written as\n",
    "\n",
    "\\begin{align*}\n",
    "  &\\phantom{=..} \\left(1 - \\sum_{i=1}^p\\phi_iL^i\\right)\\left(1 - \\sum_{i=1}^P\\Phi_iL^{im}\\right)(1-L)^d(1-L^m)^DX_t \\\\\n",
    "  &= \\left(1 + \\sum_{j=1}^q \\psi_jL^j\\right)\\left(1 + \\sum_{j=1}^Q \\Psi_jL^{jm}\\right)\\epsilon_t\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fitting a SARIMA Model\n",
    "Finding the right SARIMA model for a given time series requires a bit of experience. In the following we are going to\n",
    "review some available techniques on NYC taxi passengers data set. This data set contains the number of taxi\n",
    "passengers in New York City in 30 minute time intervals.\n",
    "\n",
    "There are at least five known anomalies in the data set. These are:\n",
    "- NYC Marathon - 2014-11-02\n",
    "- Thanksgiving - 2014-11-27\n",
    "- Christmas - 2014-12-25\n",
    "- New Years - 2015-01-01\n",
    "- Snow Blizzard - 2015-01-26 and 2015-01-27\n",
    "\n",
    "\n",
    "First, we inspect the data visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '../data/nyc_taxi/nyc_taxi.csv',\n",
    "    index_col='timestamp'\n",
    ")\n",
    "\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fitting a SARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=2)\n",
    "\n",
    "df.plot(ax=axes[0])\n",
    "df.iloc[:7*48].plot(ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fitting a SARIMA Model\n",
    "Since our anomalies are specified on day level, we resample our dataset to a one-day resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = df.resample('1D').mean()\n",
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fitting a SARIMA Model\n",
    "There is no obvious trend in the data, but we can observe a seasonal pattern. Next, we try to determine good values for\n",
    "$p, q, P, Q$ and $m$ using the ACF and PACF plots. Some useful rules of thumb are:\n",
    "- $q$: Take the first point where the ACF plot meets the significance threshold.\n",
    "- $p$: Take the point where the PACF plot first meets the significance threshold.\n",
    "- $m$: Take the point with the highest value in the ACF plot.\n",
    "- $P$: Take $P \\geq 1$ if the ACF at $m$ is positive else $0$.\n",
    "- $Q$: Take $Q\\geq 1$ if the ACF at $m$ is negative else $0$.\n",
    "- $D$: Choose $D=1$ if the seasonal pattern (if present) is stable over time and else $D=0$.\n",
    "- Usually $d+D \\leq 2$ and $P+Q\\leq 2$.\n",
    "\n",
    "*Note*: If we would observe a trend in the data then we would first difference the series until the trend disappears\n",
    "before we compute the ACF and PACF plots. The order of differencing equals the $d$ value in our SARIMA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fitting a SARIMA Model\n",
    "- We have already observed a stable seasonal pattern $\\Rightarrow$ $D=1$\n",
    "- We plot the ACF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "tsaplots.plot_acf(df, lags=48, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Question:** Try to determine the period of the seasonal pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "source": [
    "- In the first plot we observe that the highest correlation is at a lag of $7$ days $\\Rightarrow$ $m=7$.\n",
    "- The correlation at $m$ is positive hence we assume $P \\geq 1$ and $Q=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fitting a SARIMA Model\n",
    "We apply seasonal differencing to find a value for $q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "tsaplots.plot_acf(df.diff(7).dropna(), lags=48, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Question:** Try to determine the order of the moving average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "source": [
    "- We see in the second plot that the autocorrelation meets the significance threshold at a lag of $3$ $\\Rightarrow$\n",
    "  $q=3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Partial Autocorrelation Function\n",
    "A related and also important function is the *partial autocorrelation function (pacf)*. The pacf measures the\n",
    "conditional correlation between a variable, and the lagged versions of itself given that we know the values of all lagged\n",
    "versions in between. For stationary SARIMA processes:\n",
    "\n",
    "$\\mathrm{pacf}(k) = \\frac{\\mathrm{Cov}(X_t, X_{t+k} \\mid X_{t+1}, \\ldots, X_{t+k-1})}{\\sqrt{\\mathrm{Var}(X_t\\mid X_{t+1},\n",
    "    \\ldots, X_{t+k-1})\\mathrm{Var}(X_{t+k}\\mid X_{t+1}, \\ldots, X_{t+k-1})}}$\n",
    "\n",
    "The pacf is better suited to choose values for $p$ since a purely autoregressive process of order $k$ has\n",
    "$\\mathrm{pacf}(\\ell) = 0$ for all $\\ell > k$.\n",
    "\n",
    "Next, we plot the PACF for our series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fitting a SARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "tsaplots.plot_pacf(df.diff(7).dropna(), lags=60, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Question:** Try to determine the order of the autoregressive part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "source": [
    "- The PACF plot falls below the significance threshold after lag $1$ $\\Rightarrow$ $p=1$\n",
    "\n",
    "We conclude that $\\mathrm{SARIMA}(1,0,3)(1,1,0)_{7}$ might be a good model for our time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fitting a SARIMA Model\n",
    "Finally, we fit the model on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.statespace.SARIMAX(df, order=(1, 0, 3), seasonal_order=(1, 1, 0, 7))\n",
    "result = model.fit(disp=False)\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fitting a SARIMA Model\n",
    "We can use one step ahead prediction on our time series to perform anomaly detection.\n",
    "Statsmodels provides a confidence interval with the prediction based on the estimated variance of the error terms.\n",
    "We mark a point as anomaly if the true value falls outside the confidence interval of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prediction = result.get_prediction(start='2014-07-14')\n",
    "prediction_mean = prediction.predicted_mean\n",
    "prediction_ci = prediction.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10,5))\n",
    "df.plot(ax=ax)\n",
    "prediction_mean.plot(style='g--', ax=ax)\n",
    "ax.fill_between(prediction_ci.index, prediction_ci.iloc[:,0], prediction_ci.iloc[:,1], color='g', alpha=0.1)\n",
    "\n",
    "threshold = (prediction_ci.iloc[:,1] - prediction_mean)\n",
    "mask = (prediction_mean - df['value'].iloc[14:]).abs() > threshold\n",
    "outlier = df.iloc[14:][mask]\n",
    "ax.scatter(outlier.index, df.loc[outlier.index], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fitting a SARIMA Model\n",
    "We compare the list of known anomalies with our detection\n",
    "- NYC Marathon - 2014-11-02\n",
    "- Thanksgiving - 2014-11-27\n",
    "- Christmas - 2014-12-25\n",
    "- New Years - 2015-01-01\n",
    "- Snow Blizzard - 2015-01-26\n",
    "- Snow Blizzard - 2015-01-27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question:** Compare our result and the known anomalies. Do you spot anything notable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Summary\n",
    "We have learned a simple way of choosing a SARIMA model for a given time series:\n",
    "- Determine the period of possible seasonality.\n",
    "- Find the order of (seasonal) differencing that is necessary to make the time series stationary.\n",
    "- Determine candidates for $q, P, Q$ from the acf plot.\n",
    "- Determine candidates for $p$ from the pacf plot\n",
    "\n",
    "## Implementations\n",
    "- Statsmodels: [statsmodels.tsa.statespace.sarimax.SARIMAX](https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html)\n",
    "\n",
    "### Other Time Series Analysis Packages\n",
    "- Prophet: [time series forecasting](https://facebook.github.io/prophet/)\n",
    "- Orbit: [Bayesian time series forecasting](https://github.com/uber/orbit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.png\" alt=\"Snow\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\">Thank you for the attention, this concludes the A.D. training. </div>\n",
    "<div class=\"md-slide title\">We will be happy to see you in another Transferlab training soon!</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n"
    ]
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
